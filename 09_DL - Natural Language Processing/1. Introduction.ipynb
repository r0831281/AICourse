{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "Natural Language Processing (NLP) is the field of Artificial Intelligence concerned with the processing, understanding, and generation of human language. It is used extensively in search engines, conversational interfaces, document processors, and so on. Machines can handle structured data well, even semi-structured data like images, but when it comes to working with free-form text, they have a hard time. Language and text is very versatile.\n",
    "\n",
    "The goal of NLP is to develop algorithms that enable computers to understand free-form text, understand the information embedded in that text, and even generate an answer if it was a question. \n",
    "\n",
    "# High level overview of NLP\n",
    "\n",
    "Let's first get started with a general and high level, but pretty complete, overview of the field of NLP.\n",
    "\n",
    "<a href=\"https://www.youtube.com/watch?v=ZifynN2oyhs&ab_channel=AssemblyAI\"><img src=\"resources/NLP_overview.png\" width=\"800\"></a>\n",
    "\n",
    "\n",
    "In the next video (from 0:00 till 7:47) we'll dive a little deeper into the details of NLP\n",
    "\n",
    "\n",
    "<a href=\"https://www.youtube.com/embed/oi0JXuL19TA?si=-8QG1G4aqUynjxfw?end=747\"><img src=\"resources/NLP_video.png\" width=\"800\"></a>\n",
    "\n",
    "\n",
    "# Natural Language Understanding (NLU)\n",
    "\n",
    "NLU involves encoding free-form text in a way that allows us to process and model it effectively. By transforming text into knowledge representations, we create vectors that capture essential information. For instance, when processing an email, an NLU system generates a vector embodying crucial details—enabling classification (e.g., HR, finance, or legal).\n",
    "\n",
    "**Encoder models** combine free-form texts into relevant vector representations aligned with specific domains.\n",
    "\n",
    "# Natural Language Generation (NLG)\n",
    "\n",
    "NLG complements NLU by creating human-like text from structured data or other non-linguistic inputs. NLG systems transform this information into coherent sentences, paragraphs, or longer texts. Think of NLG as the counterpart to NLU—it focuses on generating meaningful content from structured input. **Decoder models** play a key role in NLG, converting encoded vectors into expressive, contextually appropriate language. \n",
    "\n",
    "## Word Meaning:\n",
    "\n",
    "Words themselves lack inherent meaning. Their significance arises from context and usage.\n",
    "AI systems must learn the meaning of words, disambiguate homonyms, and handle potential mistakes (like typos or slang).\n",
    "\n",
    "## Representing and Comparing Words:\n",
    "\n",
    "Count Vectors: These provide a simple way to compare words based on their co-occurrence in sentences. However, they demand significant storage space.\n",
    "Word Embeddings: Unsupervised learning techniques create word representations. These embeddings reveal semantic relationships. For instance, similar words cluster together.\n",
    "Visualizing Word Clusters: By plotting word embeddings, we can visualize how words relate to each other in a high-dimensional space.\n",
    "Encoder-Decoder Models: These capture sentence meaning by encoding words into a shared representation. Recurrent Neural Networks (RNNs) are common examples. They enable predictions for the next word in a sequence.\n",
    "\n",
    "# Core NLP techniques:\n",
    "\n",
    "## Tokenization:\n",
    "\n",
    "Tokenization is the process of converting a sequence of characters into a sequence of tokens. In the context of NLP, tokens typically represent words, phrases, or other meaningful elements of language.\n",
    "It’s a critical first step in NLP, because it transforms raw text into an organized structure that a machine learning model can understand and analyze. By breaking down text into tokens, we can start to analyze the frequency and distribution of words, which is essential for many NLP tasks.\n",
    "\n",
    "## Stemming & Lemmatization:\n",
    "\n",
    "Stemming (& lemmatization) is a technique used to reduce words to their root form. For instance in the case of stemming: it involves chopping off the ends of words to find the base or stem. For example, “running,” “runner,” and “runs” all stem to “run.”\n",
    "This simplification is particularly useful in search engines and text classification where the exact form of a word is less important than the general meaning. Stemming helps in reducing the complexity of the text and improves the performance of NLP models.\n",
    "Lemmatization is a technique to reduce words back to their root form, but using a dictionary.\n",
    "\n",
    "## Named Entity Recognition (NER):\n",
    "\n",
    "NER is a method by which an AI system finds and classifies named entities in text into predefined categories such as names of people, organizations, locations, dates, etc.\n",
    "It’s a key part of information extraction that allows us to quickly understand and organize large amounts of data by highlighting the most important pieces of information.\n",
    "\n",
    "## Additional Preprocessing Techniques:\n",
    "\n",
    "**Stop Words Removal**: In NLP, stop words like “the,” “is,” and “and” are often removed from the text. These words are filtered out because they are common and do not carry significant meaning.\n",
    "Other steps might include **normalizing text** by converting it to lowercase, removing punctuation, correcting spelling errors, and more. These steps are crucial for reducing noise in the data and improving the accuracy of subsequent NLP tasks.\n",
    "\n",
    "Together, these preprocessing techniques lay the groundwork for more complex NLP tasks, such as sentiment analysis, machine translation, and question-answering systems. They help in transforming raw text into a more structured form that’s amenable to analysis and insight extraction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('DL_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "775b7576bf7a34da706ed620d7f0d2338b0743a1fe22363e0994f105195362b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
